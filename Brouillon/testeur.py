import nltk
import nltk, re, pprint
import os
import string
import xml.etree.ElementTree as ET

from nltk.grammar import DependencyGrammar
from nltk.parse import (DependencyGraph,ProjectiveDependencyParser,NonprojectiveDependencyParser,)
from nltk.sem import relextract

from nltk.tree import *
from nltk import word_tokenize
from nltk.stem.porter import PorterStemmer
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.tag import pos_tag
from nltk.corpus import stopwords
from nltk.corpus import wordnet as wn
from nltk.chunk import conlltags2tree, tree2conlltags
from nltk.corpus import conll2002

from nltk import ne_chunk, pos_tag
from nltk.tree import *

from collections import defaultdict
from pprint import pprint


from nltk.tree import Tree
from nltk.grammar import Nonterminal
from nltk.sem.relextract import _join, list2sym
from collections import defaultdict
from nltk.sem.relextract import rtuple

T="John Baughman: former American police officer who pushed his second wife from the roof of the Royal Antiguan Hotel in 1995; suspected of killing a close friend and first wife back in the USA; committed suicide in 2000."

ROOT = 'ROOT'
def getNodesString(parent):
    for node in parent:
        if type(node) is nltk.Tree:
            if node.label() == ROOT:
                print(ROOT)
                # print ("======== Sentence =========")
                # print ("Sentence:", " ".join(node.leaves()))
            else:
                print("--",node)
                # print ("Label:", node.label())
                # print ("Leaves:", node.leaves())

            getNodes(node)
        else:
            print ("Word:", node)



def semi_rel2reldict(pairs, window=5, trace=False):
    """
        Converts the pairs generated by ``tree2semi_rel`` into a 'reldict': a dictionary which
        stores information about the subject and object NEs plus the filler between them.
        Additionally, a left and right context of length =< window are captured (within
        a given input sentence).
        :param pairs: a pair of list(str) and ``Tree``, as generated by
        :param window: a threshold for the number of items to include in the left and right context
        :type window: int
        :return: 'relation' dictionaries whose keys are 'lcon', 'subjclass', 'subjtext', 'subjsym', 'filler', objclass', objtext', 'objsym' and 'rcon'
        :rtype: list(defaultdict)
    """
    result = []
    while len(pairs) >= 2:
        reldict = defaultdict(str)
        reldict['lcon'] = _join(pairs[0][0][-window:])
        reldict['subjclass'] = pairs[0][1].label()
        reldict['subjtext'] = _join(pairs[0][1].leaves())
        reldict['subjsym'] = list2sym(pairs[0][1].leaves())
        reldict['filler'] = _join(pairs[1][0])
        reldict['untagged_filler'] = _join(pairs[1][0], untag=True)
        reldict['objclass'] = pairs[1][1].label()
        reldict['objtext'] = _join(pairs[1][1].leaves())
        reldict['objsym'] = list2sym(pairs[1][1].leaves())
        reldict['rcon'] = []
        if trace:
            print("(%s(%s, %s)" % (reldict['untagged_filler'], reldict['subjclass'], reldict['objclass']))
        result.append(reldict)
        pairs = pairs[1:]
    return result

# for text in nltk.sent_tokenize(T):
text=T
# text = "Tom is the cofounder of Microsoft"
chunked = ne_chunk(pos_tag(word_tokenize(text)))
# print(relextract.tree2semi_rel(chunked))
# print(semi_rel2reldict(relextract.tree2semi_rel(chunked)))

pattern = re.compile(r'.*\bin\b(?!\b.+ing)')#(r'.*\bof\b.*')(r'(ab)*')#
reldicts = semi_rel2reldict(relextract.tree2semi_rel(chunked))

subjclass = 'PERSON'
objclass = 'ORGANIZATION'
window = 5
relfilter = lambda x: (x['subjclass'] == 'PERSON' or x['subjclass'] == "ORGANIZATION"  or x['objclass']==objclass)


pattern='''
NP: {<DT>? <JJ>* <NN*>*} # NP
NNS: {<NNS>*}
V: {<V.*>}    # Verb
CD: {<CD>*}   #date
'''
# pattern='''  NP: {<DT>? <JJ>* <NN>*} # NP
#     P: {<IN>}           # Preposition
#
#     '''

res=""

rels = list(filter(relfilter, reldicts))
for rel in rels:
    # rel[]
    # pprint(rtuple(rel))
    if len(rel["untagged_filler"])>0:
        tagged = pos_tag(word_tokenize(rel["untagged_filler"]))
        cp = nltk.RegexpParser(pattern)
        cs = cp.parse(tagged)
        #reccuperation conlltags
        iob_tagged = nltk.tree2conlltags(cs)
        ne_tree = conlltags2tree(iob_tagged)
        # print(ne_tree)

        phrase=[[]]
        i=0
        for iob in iob_tagged:
            # print(iob)
            if len(iob)>0:
                if iob[2]!="O":
                    phrase[i].append(iob)
                else:
                    if phrase[i]!=[]:
                        i+=1
                        phrase.append([])
        # pprint(phrase)


reldicts

class doc:
    pass



for rel in reldicts:
    for k, v in sorted(rel.items()):
        print(k, '=>', v) # doctest: +ELLIPSIS
        a=1
    print('=' * 40)

    print(rel['subjtext'])
    print(rel['filler'])
    print(rel['objtext'])


    print('=' * 40)

    IN = re.compile(r'')#r'.*\bin\b(?!\b.+ing\b)')

    doc.headline=['foo']
    doc.text=ne_tree

    print("="*50)
    for rel in relextract.extract_rels('PER','PER', doc, corpus='ieer'):
        print(relextract.rtuple(rel))  # doctest: +ELLIPSIS
    print("="*50)


# , pattern = IN)




a=1
